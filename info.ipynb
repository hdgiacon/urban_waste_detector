{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def explorar_chaves(d, nivel = 0):\n",
    "    if isinstance(d, dict):\n",
    "        for chave, valor in d.items():\n",
    "            print(\"  \" * nivel + f\"Chave: {chave}\")\n",
    "            \n",
    "            explorar_chaves(valor, nivel + 1)\n",
    "    \n",
    "    elif isinstance(d, list) and len(d) > 0:\n",
    "        print(\"  \" * nivel + f\"Lista com {len(d)} elementos - mostrando chaves do primeiro elemento:\")\n",
    "        \n",
    "        explorar_chaves(d[0], nivel + 1)\n",
    "\n",
    "with open('data/annotations.json', 'r') as arquivo_json:\n",
    "    dados = json.load(arquivo_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chave: info\n",
      "  Chave: year\n",
      "  Chave: version\n",
      "  Chave: description\n",
      "  Chave: contributor\n",
      "  Chave: url\n",
      "  Chave: date_created\n",
      "Chave: images\n",
      "  Lista com 1500 elementos - mostrando chaves do primeiro elemento:\n",
      "    Chave: id\n",
      "    Chave: width\n",
      "    Chave: height\n",
      "    Chave: file_name\n",
      "    Chave: license\n",
      "    Chave: flickr_url\n",
      "    Chave: coco_url\n",
      "    Chave: date_captured\n",
      "    Chave: flickr_640_url\n",
      "Chave: annotations\n",
      "  Lista com 4784 elementos - mostrando chaves do primeiro elemento:\n",
      "    Chave: id\n",
      "    Chave: image_id\n",
      "    Chave: category_id\n",
      "    Chave: segmentation\n",
      "      Lista com 1 elementos - mostrando chaves do primeiro elemento:\n",
      "        Lista com 158 elementos - mostrando chaves do primeiro elemento:\n",
      "    Chave: area\n",
      "    Chave: bbox\n",
      "      Lista com 4 elementos - mostrando chaves do primeiro elemento:\n",
      "    Chave: iscrowd\n",
      "Chave: scene_annotations\n",
      "  Lista com 4296 elementos - mostrando chaves do primeiro elemento:\n",
      "    Chave: image_id\n",
      "    Chave: background_ids\n",
      "      Lista com 1 elementos - mostrando chaves do primeiro elemento:\n",
      "Chave: licenses\n",
      "Chave: categories\n",
      "  Lista com 60 elementos - mostrando chaves do primeiro elemento:\n",
      "    Chave: supercategory\n",
      "    Chave: id\n",
      "    Chave: name\n",
      "Chave: scene_categories\n",
      "  Lista com 7 elementos - mostrando chaves do primeiro elemento:\n",
      "    Chave: id\n",
      "    Chave: name\n"
     ]
    }
   ],
   "source": [
    "explorar_chaves(dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversão completa! Anotações salvas em labels_yolo/.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "coco_annotation_path = 'data/annotations.json'\n",
    "\n",
    "output_dir = 'labels_yolo/'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok = True)\n",
    "\n",
    "with open(coco_annotation_path) as f:\n",
    "    coco = json.load(f)\n",
    "\n",
    "categories = {cat['id']: cat['name'] for cat in coco['categories']}\n",
    "category_mapping = {cat['id']: idx for idx, cat in enumerate(coco['categories'])}\n",
    "\n",
    "def convert_bbox(size, bbox):\n",
    "    dw = 1. / size[0]\n",
    "    dh = 1. / size[1]\n",
    "    x = bbox[0] + bbox[2] / 2.0  \n",
    "    y = bbox[1] + bbox[3] / 2.0  \n",
    "    w = bbox[2]  \n",
    "    h = bbox[3]  \n",
    "    x = x * dw\n",
    "    w = w * dw\n",
    "    y = y * dh\n",
    "    h = h * dh\n",
    "    return (x, y, w, h)\n",
    "\n",
    "\n",
    "image_info = {img['id']: img for img in coco['images']}\n",
    "\n",
    "\n",
    "for annotation in coco['annotations']:\n",
    "    image_id = annotation['image_id']\n",
    "    category_id = annotation['category_id']\n",
    "    bbox = annotation['bbox']\n",
    "\n",
    "    image = image_info[image_id]\n",
    "    file_name = image['file_name']\n",
    "    width = image['width']\n",
    "    height = image['height']\n",
    "\n",
    "    txt_file_path = os.path.join(output_dir, file_name.replace('.jpg', '.txt'))\n",
    "\n",
    "    os.makedirs(os.path.dirname(txt_file_path), exist_ok = True)\n",
    "\n",
    "    yolo_bbox = convert_bbox((width, height), bbox)\n",
    "\n",
    "    yolo_class_id = category_mapping[category_id]\n",
    "\n",
    "    with open(txt_file_path, 'a') as label_file:\n",
    "        label_file.write(f\"{yolo_class_id} \" + \" \".join([f\"{a:.6f}\" for a in yolo_bbox]) + '\\n')\n",
    "\n",
    "print(f\"Conversão completa! Anotações salvas em {output_dir}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos reorganizados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "data_path = 'data'\n",
    "labels_path = 'labels_yolo'\n",
    "\n",
    "new_dataset_path = 'dataset_prov'\n",
    "new_images_path = os.path.join(new_dataset_path, 'images')\n",
    "new_labels_path = os.path.join(new_dataset_path, 'labels')\n",
    "\n",
    "os.makedirs(new_images_path, exist_ok = True)\n",
    "os.makedirs(new_labels_path, exist_ok = True)\n",
    "\n",
    "def move_files_from_batches(batch_folder, target_folder, extension):\n",
    "    for batch in os.listdir(batch_folder):\n",
    "        batch_path = os.path.join(batch_folder, batch)\n",
    "        \n",
    "        if os.path.isdir(batch_path):\n",
    "            for file in os.listdir(batch_path):\n",
    "                if file.endswith(extension):\n",
    "                    base_name = os.path.splitext(file)[0]\n",
    "                    new_file_name = f\"{base_name}_{batch}{extension}\"\n",
    "                    \n",
    "                    source_file = os.path.join(batch_path, file)\n",
    "                    target_file = os.path.join(target_folder, new_file_name)\n",
    "                    \n",
    "                    shutil.copy(source_file, target_file)\n",
    "\n",
    "move_files_from_batches(data_path, new_images_path, '.jpg')\n",
    "\n",
    "move_files_from_batches(labels_path, new_labels_path, '.txt')\n",
    "\n",
    "print(\"Arquivos reorganizados com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divisão e cópia de arquivos concluídas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "prov_images_dir = 'dataset_prov/images'\n",
    "prov_labels_dir = 'dataset_prov/labels'\n",
    "output_dir = 'dataset'\n",
    "\n",
    "train_images_dir = os.path.join(output_dir, 'images', 'train')\n",
    "val_images_dir = os.path.join(output_dir, 'images', 'val')\n",
    "train_labels_dir = os.path.join(output_dir, 'labels', 'train')\n",
    "val_labels_dir = os.path.join(output_dir, 'labels', 'val')\n",
    "\n",
    "os.makedirs(train_images_dir, exist_ok = True)\n",
    "os.makedirs(val_images_dir, exist_ok = True)\n",
    "os.makedirs(train_labels_dir, exist_ok = True)\n",
    "os.makedirs(val_labels_dir, exist_ok = True)\n",
    "\n",
    "image_files = []\n",
    "label_files = []\n",
    "\n",
    "for img_file in os.listdir(prov_images_dir):\n",
    "    if img_file.endswith('.jpg'):\n",
    "        img_path = os.path.join(prov_images_dir, img_file)\n",
    "        label_path = os.path.join(prov_labels_dir, img_file.replace('.jpg', '.txt'))\n",
    "        \n",
    "        if os.path.isfile(label_path):\n",
    "            image_files.append(img_path)\n",
    "            label_files.append(label_path)\n",
    "\n",
    "train_imgs, val_imgs, train_labels, val_labels = train_test_split(\n",
    "    image_files, label_files, test_size = 0.2, random_state = 42\n",
    ")\n",
    "\n",
    "for img_path, label_path in zip(train_imgs, train_labels):\n",
    "    shutil.copy(img_path, train_images_dir)\n",
    "    shutil.copy(label_path, train_labels_dir)\n",
    "\n",
    "for img_path, label_path in zip(val_imgs, val_labels):\n",
    "    shutil.copy(img_path, val_images_dir)\n",
    "    shutil.copy(label_path, val_labels_dir)\n",
    "\n",
    "print(\"Divisão e cópia de arquivos concluídas com sucesso!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
